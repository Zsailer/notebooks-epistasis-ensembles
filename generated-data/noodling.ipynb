{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pickle\n",
    "from latticeproteins.sequences import hamming_distance\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Main Code\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "def testing(dataset, d):\n",
    "    # Collect bad datasets\n",
    "\n",
    "    # Iterate through many dataset\n",
    "        # Read in actual dataset\n",
    "        with open(\"example-prediction/walks-actual-\"+str(d)+\".pickle\", \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            edges0 = data[\"edges\"]\n",
    "            seq = data[\"seq\"]\n",
    "            target = data[\"target\"]\n",
    "            temp = data[\"temp\"]\n",
    "            db = data[\"db\"]\n",
    "\n",
    "        # Read in predicted dataset\n",
    "        with open(\"example-prediction/walks-predicted-\"+str(d)+\".pickle\", \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            edges1 = data[\"edges\"]\n",
    "            \n",
    "        # Read in predicted dataset\n",
    "        with open(\"example-prediction/walks-predicted2-\"+str(d)+\".pickle\", \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            edges2 = data[\"edges\"]\n",
    "\n",
    "        # Construct as networks\n",
    "        G0, G1, G2 = build_graphs(edges0, edges1, edges2, seq)\n",
    "        return G0, G1, G2, seq\n",
    "\n",
    "    \n",
    "# ----------------------------------------------------------\n",
    "# Functions used in this code.\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "def retrieve(dataset, d):\n",
    "    import os\n",
    "    remote_path = \"epistasis-ensembles-scripts/{:}/results\".format(dataset)\n",
    "    local_path = os.getcwd() + \"/example-prediction/\".format(dataset)\n",
    "    part0 = \"/walks-actual-{:}.pickle\".format(d)\n",
    "    part1 = \"/walks-predicted-{:}.pickle\".format(d)\n",
    "    part2 = \"/walks-predicted2-{:}.pickle\".format(d)   \n",
    "\n",
    "    if False in [os.path.isfile(local_path + part1), os.path.isfile(local_path + part2)]:        \n",
    "        import paramiko\n",
    "\n",
    "        ssh = paramiko.SSHClient()\n",
    "        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "        ssh.connect('aciss.uoregon.edu', username='zsailer', password='Za12ch#$')\n",
    "\n",
    "        sftp = ssh.open_sftp()\n",
    "        sftp.get(remote_path + part0, local_path + part0) \n",
    "        sftp.get(remote_path + part1, local_path + part1) \n",
    "        sftp.get(remote_path + part2, local_path + part2) \n",
    "        sftp.close() \n",
    "        print(\"downloaded!\")\n",
    "    \n",
    "# ----------------------------------------------------------\n",
    "# Functions used in this code.\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "def flux_out_of_node(G, node_i):\n",
    "    \"\"\"Determine \"\"\"\n",
    "    # Get flux coming from source\n",
    "    total_flux_avail = G.node[node_i][\"flux\"]\n",
    "    \n",
    "    edges = {}\n",
    "    # Normalize the transition probability from source\n",
    "    norm = sum([G.edge[node_i][node_j][\"weight\"] for node_j in G.neighbors(node_i)])\n",
    "    #print(norm)\n",
    "    # Iterate over neighbors divvy up flux across neighbors\n",
    "    for node_j in G.neighbors(node_i):\n",
    "        if norm > 0:\n",
    "            fixation = G.edge[node_i][node_j][\"weight\"]\n",
    "            dflux = (fixation/norm) * total_flux_avail\n",
    "            G.edge[node_i][node_j][\"delta_flux\"] = dflux\n",
    "            G.node[node_j][\"flux\"] += dflux\n",
    "        else:\n",
    "            G.edge[node_i][node_j][\"delta_flux\"] = 0\n",
    "    return edges\n",
    "\n",
    "def flux_from_source(G, source):\n",
    "    # Reset the flux of each node\n",
    "    init_flux = dict([(node, 0) for node in G.nodes()])\n",
    "    nx.set_node_attributes(G, \"flux\", init_flux)\n",
    "    G.node[source][\"flux\"] = 1\n",
    "    # Add flux to each node.\n",
    "    levels = ring_levels(G, source)\n",
    "    for l in levels:\n",
    "        for node_i in levels[l]:\n",
    "            edges = flux_out_of_node(G, node_i)\n",
    "            for key, flux_to_add in edges.items():\n",
    "                node_i, node_j = key\n",
    "                G.node[node_j][\"flux\"] += flux_to_add\n",
    "    return G\n",
    "\n",
    "def ring_levels(G, root):\n",
    "    levels = dict([(i,[]) for i in range(20)])\n",
    "    levels[0].append(root)\n",
    "    for node in G.nodes():\n",
    "        neighbors = G.neighbors(node)\n",
    "        for neigh in neighbors:\n",
    "            key = hamming_distance(root, neigh)\n",
    "            levels[key].append(neigh)\n",
    "    for key, val in levels.items():\n",
    "        z = sorted(list(set(val)))\n",
    "        levels[key] = z\n",
    "    return levels\n",
    "\n",
    "def build_graphs(edges0, edges1, edges2, source):\n",
    "    \"\"\"Construct two different networks from a set of edges.\n",
    "    \"\"\"\n",
    "    # -----------------------------------------------\n",
    "    # build initial graphs\n",
    "    # -----------------------------------------------\n",
    "\n",
    "    # Build Graph\n",
    "    G0 = nx.DiGraph()\n",
    "    for key, weight in edges0:\n",
    "        i,j = key[0], key[1]\n",
    "        G0.add_edge(i,j, weight=weight[\"weight\"])\n",
    "        \n",
    "    G1 = nx.DiGraph()\n",
    "    for key, weight in edges1:\n",
    "        i,j = key[0], key[1]\n",
    "        G1.add_edge(i,j, weight=weight[\"weight\"])\n",
    "        \n",
    "    # Build Graph\n",
    "    G2 = nx.DiGraph()\n",
    "    for key, weight in edges2:\n",
    "        i,j = key[0], key[1]\n",
    "        G2.add_edge(i,j, weight=weight[\"weight\"])\n",
    "\n",
    "    seq = source\n",
    "    \n",
    "    # -----------------------------------------------\n",
    "    # Calculate the flux at each node and edge\n",
    "    # -----------------------------------------------\n",
    "    \n",
    "    G0 = flux_from_source(G0, seq)\n",
    "    G1 = flux_from_source(G1, seq)\n",
    "    G2 = flux_from_source(G2, seq)\n",
    "\n",
    "    return G0, G1, G2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radial(r, theta):\n",
    "    return (r*np.cos(theta), r*np.sin(theta))\n",
    "\n",
    "def ring_position(G, root):\n",
    "    import random\n",
    "    levels = ring_levels(G, root)\n",
    "    pos = {}\n",
    "    for i in range(len(levels)):\n",
    "        nodes = levels[i]\n",
    "        nodelist = list(nodes)\n",
    "        random.shuffle(nodelist)\n",
    "        rotate_translate = random.random()\n",
    "        for j, node in enumerate(nodelist):\n",
    "            angle = 2*np.pi / len(nodes)\n",
    "            pos[node] = radial(i, j*angle + + rotate_translate)\n",
    "    return pos\n",
    "\n",
    "\n",
    "def modified_Gdiff(G0, G2):\n",
    "    # Get a dictionary of change in fluxes along each edge.\n",
    "    edges_0 = dict([((i, j), G0.edge[i][j][\"delta_flux\"]) for i,j in G0.edges()])\n",
    "    edges_2 = dict([((i, j), G2.edge[i][j][\"delta_flux\"]) for i,j in G2.edges()])\n",
    "\n",
    "    # -----------------------------------------------\n",
    "    # Calculate the change in delta_flux on each edge\n",
    "    # -----------------------------------------------\n",
    "    edges_diff = {}\n",
    "    # See what edges we lost\n",
    "    for key, val in edges_0.items():\n",
    "        if key in edges_2:\n",
    "            weight = edges_2[key] - edges_0[key]\n",
    "            if weight < 0:\n",
    "                # This edge gained flux\n",
    "                color = \"r\"\n",
    "            else:\n",
    "                # This edge lost flux\n",
    "                color = \"b\"\n",
    "            edges_diff[key] = dict(color=color, weight=abs(weight))\n",
    "        else:\n",
    "            # This edge was lost in our predictions\n",
    "            edges_diff[key] = dict(weight=val, color=\"r\")\n",
    "\n",
    "    # See what edges we gained.\n",
    "    for key, val in edges_2.items():\n",
    "        if key in edges_0:\n",
    "            pass\n",
    "        else:\n",
    "            # This edge was gained in our predictions\n",
    "            edges_diff[key] = dict(weight=val, color=\"b\")\n",
    "\n",
    "    # -----------------------------------------------\n",
    "    # Calculate the change in flux at each node\n",
    "    # -----------------------------------------------\n",
    "    nodes_0 = dict([(i, G0.node[i][\"flux\"]) for i in G0.nodes()])\n",
    "    nodes_2 = dict([(i, G2.node[i][\"flux\"]) for i in G2.nodes()])\n",
    "\n",
    "    node_diff = {}\n",
    "    for key, val in nodes_0.items():\n",
    "        if key in nodes_2:\n",
    "            diff = nodes_2[key] - val\n",
    "            if diff > 0:\n",
    "                color = \"b\"\n",
    "            else:\n",
    "                color = \"r\"\n",
    "            node_diff[key] = dict(color=color, outer=nodes_2[key], inner=val)\n",
    "        else:\n",
    "            node_diff[key] = dict(color=\"r\", outer=nodes_0[key], inner=0)\n",
    "\n",
    "    for key, val in nodes_2.items():\n",
    "        if key in nodes_0:\n",
    "            pass\n",
    "        else:\n",
    "            node_diff[key] = dict(color=\"b\", outer=val, inner=0)\n",
    "\n",
    "    # -----------------------------------------------\n",
    "    # Construct a network of differences\n",
    "    # -----------------------------------------------\n",
    "    Gdiff = nx.DiGraph()\n",
    "    for key, val in edges_diff.items():\n",
    "        Gdiff.add_edge(key[0],key[1],**val)\n",
    "\n",
    "    for key, val in node_diff.items():\n",
    "        Gdiff.node[key].update(**val)\n",
    "\n",
    "    return Gdiff\n",
    "\n",
    "def top_flux_path(G, seq):\n",
    "    current = seq\n",
    "    path = [seq]\n",
    "    while True:\n",
    "        neighbors = list(G.neighbors(current))\n",
    "        if len(neighbors) == 0:\n",
    "            return path\n",
    "        dflux = [G.edge[current][node][\"delta_flux\"] for node in neighbors]\n",
    "        index = np.argmax(dflux)\n",
    "        if dflux[index] == 0:\n",
    "            return path\n",
    "        current = neighbors[index]\n",
    "        path.append(current)\n",
    "\n",
    "def plot_networks(G0, G1, G2, source, pos=None):\n",
    "    \"\"\"\"\"\"\n",
    "    # options\n",
    "    node_scale = 300\n",
    "    edge_scale = 20\n",
    "    node_color = \"k\"\n",
    "    threshold = 0.01\n",
    "    \n",
    "    # Remove nodes that have small flux\n",
    "    nodes_to_remove0 = []\n",
    "    for node in G0.nodes():\n",
    "        if G0.node[node][\"flux\"] < threshold:\n",
    "            nodes_to_remove0.append(node)    \n",
    "    \n",
    "    # Remove nodes that have small flux\n",
    "    nodes_to_remove1 = []\n",
    "    for node in G1.nodes():\n",
    "        if G1.node[node][\"flux\"] < threshold:\n",
    "            nodes_to_remove1.append(node)\n",
    "\n",
    "    nodes_to_remove2 = []\n",
    "    for node in G2.nodes():\n",
    "        if G2.node[node][\"flux\"] < threshold:\n",
    "            nodes_to_remove2.append(node)\n",
    "      \n",
    "    G0.remove_nodes_from(nodes_to_remove0)\n",
    "    G1.remove_nodes_from(nodes_to_remove1)\n",
    "    G2.remove_nodes_from(nodes_to_remove2)\n",
    "   \n",
    "    path0 = top_flux_path(G0, source)\n",
    "    path2 = top_flux_path(G2, source)\n",
    "    \n",
    "    Gdiff = modified_Gdiff(G0, G2)\n",
    "    Gdiff_ = modified_Gdiff(G0, G1)\n",
    "    Gdiff__ = nx.compose(Gdiff, Gdiff_)\n",
    "    \n",
    "    from matplotlib.gridspec import GridSpec\n",
    "    from matplotlib.patches import Circle\n",
    "    \n",
    "    def draw_circles(ax):\n",
    "        \"\"\"Draw circles add increasing hamming distances for each network.\"\"\"\n",
    "        for i in range(0,8):\n",
    "            circle = Circle((0, 0), i, facecolor='none',\n",
    "                    edgecolor=\"k\", linewidth=.5, alpha=0.5, linestyle=\"--\")\n",
    "            ax.add_patch(circle)\n",
    "\n",
    "    \n",
    "    # Initialize a figure\n",
    "    fig = plt.figure(figsize=(20,8))\n",
    "    \n",
    "    # Initialize a gridspec\n",
    "    gs = GridSpec(1, 3)\n",
    "       \n",
    "    seq = source\n",
    "    # Calculate the positions for all nodes on rings\n",
    "    if pos is None:\n",
    "        pos = ring_position(Gdiff__, seq)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Draw the first network\n",
    "    # -------------------------------------------------\n",
    "    \n",
    "    ax1 = plt.subplot(gs[0, 0])\n",
    "    \n",
    "    # Draw path\n",
    "    elist = []\n",
    "    if path0 is not None:\n",
    "        ewidths = [G0.edge[path0[i-1]][path0[i]][\"delta_flux\"] for i in range(1,len(path0))]\n",
    "        elist = [(path0[i-1],path0[i]) for i in range(1,len(path0))]\n",
    "        ewidths = np.array(ewidths) * edge_scale\n",
    "        nx.draw_networkx_edges(G0, pos=pos, ax=ax1,\n",
    "           edgelist=elist,\n",
    "           width=ewidths,\n",
    "           arrows=False,\n",
    "           edge_color=\"orange\",\n",
    "           alpha=.6\n",
    "        )    \n",
    "    \n",
    "    # Set the widths of the edges to the delta flux attribute of each edge.\n",
    "    \n",
    "    edgelist = list(G0.edges())\n",
    "    for edge in elist:\n",
    "        edgelist.remove(edge)\n",
    "        \n",
    "    edge_widths = np.array([G0.edge[i][j][\"delta_flux\"] for i,j in edgelist])\n",
    "    edge_widths = edge_widths * edge_scale\n",
    "    nx.draw_networkx_edges(G0, pos=pos, ax=ax1,\n",
    "        edgelist=edgelist,\n",
    "        width=edge_widths,                \n",
    "        arrows=False,\n",
    "        edge_color=\"gray\",\n",
    "        alpha=0.6\n",
    "    )\n",
    "    \n",
    "    # Set the node sizes to the amount of flux passing through each node.\n",
    "    node_size = [G0.node[i][\"flux\"] * node_scale for i in G0.nodes()]\n",
    "    nx.draw_networkx_nodes(G0, pos=pos, ax=ax1,\n",
    "        node_size=node_size,                \n",
    "        linewidths=None,\n",
    "        node_color=node_color\n",
    "    )\n",
    "    \n",
    "    bad_nodes1 = [node for node in Gdiff.nodes() if node not in G0.nodes()]\n",
    "    bad_nodes1_size = [G2.node[node][\"flux\"] * node_scale for node in Gdiff.nodes() if node not in G0.nodes()]\n",
    "\n",
    "    nx.draw_networkx_nodes(Gdiff, pos=pos, ax=ax1,\n",
    "        nodelist = bad_nodes1,\n",
    "        node_shape = \"x\",\n",
    "        node_size = bad_nodes1_size,\n",
    "        linewidths = None,\n",
    "        node_color = \"m\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Draw circles\n",
    "    draw_circles(ax1)\n",
    "    ax1.axis(\"equal\")\n",
    "    ax1.axis(\"off\")\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    # Draw the second network\n",
    "    # -------------------------------------------------\n",
    "    \n",
    "    ax2 = plt.subplot(gs[0, 1])\n",
    "    \n",
    "    # Draw path\n",
    "    elist = []\n",
    "    if path2 is not None:\n",
    "        ewidths = [G2.edge[path2[i-1]][path2[i]][\"delta_flux\"] for i in range(1,len(path2))]\n",
    "        elist = [(path2[i-1],path2[i]) for i in range(1,len(path2))]\n",
    "        ewidths = np.array(ewidths) * edge_scale\n",
    "        nx.draw_networkx_edges(G2, pos=pos, ax=ax2,\n",
    "           edgelist=elist,\n",
    "           width=ewidths,\n",
    "           arrows=False,\n",
    "           edge_color=\"orange\",\n",
    "           alpha=0.6\n",
    "        )    \n",
    "    \n",
    "    # Set the widths of the edges to the delta flux attribute of each edge.\n",
    "    edgelist = list(G2.edges())\n",
    "    for edge in elist:\n",
    "        edgelist.remove(edge)\n",
    "    edge_widths = np.array([G2.edge[i][j][\"delta_flux\"] for i,j in edgelist])\n",
    "    edge_widths = edge_widths * edge_scale\n",
    "    nx.draw_networkx_edges(G2, pos=pos, ax=ax2,\n",
    "        edgelist=edgelist,\n",
    "        width=edge_widths,                \n",
    "        arrows=False,\n",
    "        edge_color=\"gray\",\n",
    "        alpha=0.6\n",
    "    )    \n",
    "    \n",
    "    # Set the node sizes to the amount of flux passing through each node.\n",
    "    node_size = [G2.node[i][\"flux\"] * node_scale for i in G2.nodes()]\n",
    "\n",
    "    nx.draw_networkx_nodes(G2, pos=pos, ax=ax2,\n",
    "        node_size=node_size,                \n",
    "        linewidths=None,\n",
    "        node_color=node_color\n",
    "    )\n",
    "\n",
    "    bad_nodes2 = [node for node in Gdiff.nodes() if node not in G2.nodes()]\n",
    "    bad_nodes2_size = [G0.node[node][\"flux\"] * node_scale for node in Gdiff.nodes() if node not in G2.nodes()]\n",
    "\n",
    "    nx.draw_networkx_nodes(Gdiff, pos=pos, ax=ax2,\n",
    "        nodelist = bad_nodes2,\n",
    "        node_shape = \"x\",\n",
    "        node_size = bad_nodes2_size,\n",
    "        linewidths = None,\n",
    "        node_color = \"m\"\n",
    "    )\n",
    "        \n",
    "    # Draw circles\n",
    "    draw_circles(ax2) \n",
    "    ax2.axis(\"equal\")\n",
    "    ax2.axis(\"off\")\n",
    "    \n",
    "    # -------------------------------------------------\n",
    "    # Draw difference network\n",
    "    # -------------------------------------------------\n",
    "        \n",
    "    ax3 = plt.subplot(gs[0, 2])\n",
    "\n",
    "    \n",
    "    # Set the widths of the edges to the delta flux attribute of each edge.\n",
    "    edge_widths = np.array([Gdiff.edge[i][j][\"weight\"] for i,j in Gdiff.edges()])\n",
    "    edge_widths = edge_widths * edge_scale\n",
    "    edge_color = [Gdiff.edge[i][j][\"color\"] for i,j in Gdiff.edges()]\n",
    "\n",
    "    nx.draw_networkx_edges(Gdiff, pos=pos, ax=ax3,\n",
    "        width=edge_widths,                \n",
    "        arrows=False,\n",
    "        edge_color=edge_color,\n",
    "        alpha=0.5\n",
    "    )\n",
    "    \n",
    "    # Set the node sizes to the amount of flux passing through each node.\n",
    "    node_size = [Gdiff.node[i][\"outer\"] * node_scale for i in Gdiff.nodes()]\n",
    "    node_color = [Gdiff.node[i][\"color\"]  for i in Gdiff.nodes()]\n",
    "    nx.draw_networkx_nodes(Gdiff, pos=pos, ax=ax3,\n",
    "        node_size=node_size,                \n",
    "        linewidths=None,\n",
    "        node_color=node_color\n",
    "    )\n",
    "\n",
    "    # Set the node sizes to the amount of flux passing through each node.\n",
    "    node_size = [Gdiff.node[i][\"inner\"] * node_scale for i in Gdiff.nodes()]\n",
    "    nx.draw_networkx_nodes(Gdiff, pos=pos, ax=ax3,\n",
    "        node_size=node_size,                \n",
    "        linewidths=None,\n",
    "        node_color=\"w\"\n",
    "    )    \n",
    "    \n",
    "    # Draw circles\n",
    "    draw_circles(ax3) \n",
    "\n",
    "    ax3.axis(\"equal\")\n",
    "    ax3.axis(\"off\")\n",
    "    return fig, pos\n",
    "\n",
    "def fixation(fitness1, fitness2,*args, **kwargs):\n",
    "    \"\"\" Simple Gillespie fixation probability between two organism with fitnesses 1 and 2.\n",
    "    (With infinite population size!)\n",
    "    \n",
    "    .. math::\n",
    "        p_{\\\\text{fixation}} = \\\\frac{1 - e^{-N \\\\frac{f_2-f_1}{f1}}}{1 - e^{-\\\\frac{f_2-f_1}{f1}}}\n",
    "    \"\"\"\n",
    "    sij = (fitness2 - fitness1)/abs(fitness1)\n",
    "    # Check if any nans exist if an array of fitnesses is given.\n",
    "    fixation = 1 - np.exp(-sij)\n",
    "    if type(fixation) == np.ndarray:\n",
    "        fixation = np.nan_to_num(fixation)\n",
    "        fixation[sij < 0] = 0\n",
    "    return  fixation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 41\n",
    "* 87\n",
    "* 180\n",
    "* 236\n",
    "* 237\n",
    "* 284!\n",
    "* 296!\n",
    "* 417\n",
    "* 433\n",
    "* 486\n",
    "* 487\n",
    "* 497\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"full-state-predictions\"\n",
    "d = 417\n",
    "z = 0\n",
    "for j in range(30):\n",
    "    z += 1\n",
    "    retrieve(dataset, d)\n",
    "    G0, G1, G2, seq = testing(dataset, d)\n",
    "    fig, pos = plot_networks(G0, G1, G2, seq) #, pos=pos)\n",
    "    with open(\"../figures/positions-\" + seq +\"-\"+str(d)+\"-\"+str(z)+\".pickle\", \"wb\") as f:\n",
    "        pickle.dump(pos, f)\n",
    "    plt.close()\n",
    "    fig.savefig(\"../figures/network-\" + seq +\"-\"+str(d)+\"-\"+str(z)+\"-2.pdf\", format=\"pdf\")\n",
    "    fig, pos = plot_networks(G0, G2, G1, seq, pos=pos)\n",
    "    fig.savefig(\"../figures/network-\" + seq +\"-\"+str(d)+\"-\"+str(z)+\"-1.pdf\", format=\"pdf\")\n",
    "    plt.close()\n",
    "    #print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract top trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "from latticeproteins.thermodynamics import LatticeThermodynamics\n",
    "from latticeproteins.interactions import miyazawa_jernigan\n",
    "from latticeproteins.conformations import ConformationList, Conformations\n",
    "from latticeproteins.sequences import find_differences, _residues\n",
    "from latticeproteins.evolve import monte_carlo_fixation_walk, fixation\n",
    "from latticeproteins.sequences import random_sequence, hamming_distance\n",
    "\n",
    "class PredictedLattice(object):\n",
    "    \"\"\"Predict the stability and fraction folded of any sequence with respect\n",
    "    to some wildtype lattice model. Calculates the independent effect of all mutations\n",
    "    (and pairwise effects if `double` is True) and sums those effects to predict\n",
    "    other sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, wildtype, temp, confs, double=False, target=None):\n",
    "        self.wildtype = wildtype\n",
    "        self.temp = temp\n",
    "        self.conformations = confs\n",
    "        self.target = target\n",
    "        self._lattice = LatticeThermodynamics(self.temp, self.conformations)\n",
    "        self.double = double\n",
    "\n",
    "        combos = []\n",
    "        sites = list(range(self.conformations.length()))\n",
    "        self.dG0 = self._lattice.stability(self.wildtype, target=self.target)\n",
    "\n",
    "\n",
    "        #####  Build a dictionary of additive and pairwise mutational effects ####\n",
    "        # Calculate first order coefs\n",
    "        self.dGs = {}\n",
    "        for i in sites:\n",
    "            other_sites = sites[:]\n",
    "            other_sites.remove(i)\n",
    "            for aa in _residues:\n",
    "                combos.append((i, aa))\n",
    "\n",
    "        for c in combos:\n",
    "            seq = list(self.wildtype[:])\n",
    "            seq[c[0]] = c[1]\n",
    "            # Calculate dG as dG_wt -\n",
    "            self.dGs[c] = self._lattice.stability(seq, target=self.target) - self.dG0\n",
    "\n",
    "        if self.double:\n",
    "            # Calculate second order coefs\n",
    "            combos = []\n",
    "            sites = list(range(self.conformations.length()))\n",
    "            for i in sites:\n",
    "                other_sites = sites[:]\n",
    "                other_sites.remove(i)\n",
    "                for aa in _residues:\n",
    "                    for j in other_sites:\n",
    "                        for aa2 in _residues:\n",
    "                            combos.append((i,aa,j,aa2))\n",
    "\n",
    "            for c in combos:\n",
    "                seq = list(self.wildtype[:])\n",
    "                seq[c[0]] = c[1]\n",
    "                seq[c[2]] = c[3]\n",
    "                # Calculate dG2\n",
    "                self.dGs[c] = self._lattice.stability(seq, target=self.target) - (self.dG0 + self.dGs[(c[0],c[1])]+ self.dGs[(c[2],c[3])])\n",
    "\n",
    "    def stability(self, seq, target=None):\n",
    "        \"\"\"Calculate the stability of a given sequence using the Lattice predictor\"\"\"\n",
    "        # Get additive coefs to build predictions\n",
    "        if target != self.target:\n",
    "            raise Exception(\"Target does not match wildtype target.\")\n",
    "        loci = find_differences(self.wildtype, seq)\n",
    "        # Get all additive combinations for the sequence given\n",
    "        add = [(pair[0], seq[pair[0]]) for pair in it.combinations(loci, 1)]\n",
    "        if self.double:\n",
    "            # Get all pairwise effects for the sequence given\n",
    "            pairs = [(pair[0], seq[pair[0]], pair[1], seq[pair[1]]) for pair in it.combinations(loci, 2)]\n",
    "            dgs = add + pairs\n",
    "        else:\n",
    "            dgs = add\n",
    "        # Get the wildtype stability\n",
    "        stability = float(self.dG0)\n",
    "        # Sum the mutational effects\n",
    "        for coef in dgs:\n",
    "            stability += self.dGs[coef]\n",
    "        return stability\n",
    "\n",
    "    def fracfolded(self, seq, target=None):\n",
    "        \"\"\"Calculate the fraction folded for a given sequence\"\"\"\n",
    "        return 1.0 / (1.0 + np.exp(self.stability(seq, target=target) / self.temp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up landscape\n",
    "temp = 1\n",
    "length = len(seq)\n",
    "\n",
    "confs = Conformations(length, \"database\")\n",
    "cs = confs.k_lowest_confs(seq, temp, 3)\n",
    "db1 = cs[0]\n",
    "db2 = cs[1]\n",
    "db3 = cs[2]\n",
    "\n",
    "target = cs[0]\n",
    "db = [db1, db2, db3]\n",
    "\n",
    "# Construct a lattice model calculator\n",
    "confs = Conformations(length, \"database\")\n",
    "cs = confs.k_lowest_confs(seq, temp, 3)\n",
    "target = cs[0]\n",
    "lattice = LatticeThermodynamics(temp, confs)\n",
    "plattice1 = PredictedLattice(seq, temp, confs, double=False, target=target)\n",
    "plattice2 = PredictedLattice(seq, temp, confs, double=True, target=target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
